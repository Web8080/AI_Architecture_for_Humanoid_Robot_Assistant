% ==============================================================================
% Bibliography for Humanoid Robot Assistant Research Paper
% ==============================================================================

% ==================== Large Language Models ====================

@article{brown2020gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

% ==================== Embodied AI & Robot Learning ====================

@article{ahn2022saycan,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={Conference on Robot Learning},
  year={2022}
}

@article{brohan2023rt2,
  title={RT-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@inproceedings{driess2023palme,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  booktitle={International Conference on Machine Learning},
  year={2023}
}

@article{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  journal={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023}
}

@inproceedings{shridhar2022cliport,
  title={Cliport: What and where pathways for robotic manipulation},
  author={Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle={Conference on Robot Learning},
  year={2022}
}

@article{deitke2022embodied,
  title={Embodied AI: Bridging simulation and reality},
  author={Deitke, Matt and others},
  journal={NeurIPS Datasets and Benchmarks},
  year={2022}
}

% ==================== Vision-Language Models ====================

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  year={2021}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  year={2022}
}

@article{li2023blip2,
  title={BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={International Conference on Machine Learning},
  year={2023}
}

@article{liu2023llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

% ==================== Computer Vision ====================

@inproceedings{kirillov2023sam,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@article{caron2023dinov2,
  title={DINOv2: Learning robust visual features without supervision},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

@article{yang2024depthanything,
  title={Depth anything: Unleashing the power of large-scale unlabeled data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  journal={CVPR},
  year={2024}
}

@article{campos2021orbslam3,
  title={ORB-SLAM3: An accurate open-source library for visual, visual-inertial and multi-map SLAM},
  author={Campos, Carlos and Elvira, Richard and Rodr{\'\i}guez, Juan J G{\'o}mez and Montiel, Jos{\'e} MM and Tard{\'o}s, Juan D},
  journal={IEEE Transactions on Robotics},
  volume={37},
  number={6},
  pages={1874--1890},
  year={2021}
}

@inproceedings{wang2023yolov7,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}

@misc{ultralytics2023yolov8,
  title={YOLOv8},
  author={Ultralytics},
  year={2023},
  howpublished={\url{https://github.com/ultralytics/ultralytics}}
}

% ==================== Robotics Platforms ====================

@article{macenski2022ros2,
  title={Robot operating system 2: Design, architecture, and uses in the wild},
  author={Macenski, Steven and Foote, Tully and Gerkey, Brian and Lalancette, Chris and Woodall, William},
  journal={Science Robotics},
  volume={7},
  number={66},
  year={2022}
}

@article{yamamoto2019hsr,
  title={Development of human support robot as the research platform of a domestic mobile manipulator},
  author={Yamamoto, Kimitoshi and Sugihara, Koki and Yokokohji, Yasuyoshi},
  journal={ROBOMECH Journal},
  volume={6},
  number={1},
  pages={1--15},
  year={2019}
}

@inproceedings{stasse2017talos,
  title={TALOS: A new humanoid research platform targeted for industrial applications},
  author={Stasse, Olivier and Flayols, Thomas and Budhiraja, Rohan and Giraud-Esclasse, Kevin and Carpentier, Justin and Mirabel, Joseph and Del Prete, Andrea and Sou{\`e}res, Philippe and Mansard, Nicolas and Lamiraux, Florent and others},
  booktitle={IEEE-RAS International Conference on Humanoid Robots},
  year={2017}
}

@book{spenko2018drc,
  title={The DARPA robotics challenge finals: Humanoid robots to the rescue},
  author={Spenko, Matthew and Buerger, Stephen and Iagnemma, Karl},
  year={2018},
  publisher={Springer}
}

@misc{tesla2023optimus,
  title={Tesla Bot / Optimus},
  author={Tesla},
  year={2023},
  howpublished={\url{https://www.tesla.com/AI}}
}

@misc{figure2024humanoid,
  title={Figure AI Humanoid Robot},
  author={Figure AI},
  year={2024},
  howpublished={\url{https://www.figure.ai}}
}

% ==================== Edge Computing & Optimization ====================

@inproceedings{jacob2018quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2018}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{cai2020oncefirall,
  title={Once-for-all: Train one network and specialize it for efficient deployment},
  author={Cai, Han and Gan, Chuang and Wang, Tianzhe and Zhang, Zhekai and Han, Song},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@misc{nvidia2023jetson,
  title={NVIDIA Jetson AGX Orin},
  author={NVIDIA},
  year={2023},
  howpublished={\url{https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/}}
}

@misc{nvidia2023tensorrt,
  title={NVIDIA TensorRT},
  author={NVIDIA},
  year={2023},
  howpublished={\url{https://developer.nvidia.com/tensorrt}}
}

% ==================== MLOps & Production Systems ====================

@article{paleyes2022challenges,
  title={Challenges in deploying machine learning: a survey of case studies},
  author={Paleyes, Andrei and Urma, Raoul-Gabriel and Lawrence, Neil D},
  journal={ACM Computing Surveys},
  volume={55},
  number={6},
  pages={1--29},
  year={2022}
}

@article{shankar2022operationalizing,
  title={Operationalizing machine learning: An interview study},
  author={Shankar, Shreya and Halpern, Yoni and Breck, Eric and Atwood, James and Wilson, Jimbo and Sculley, D},
  journal={arXiv preprint arXiv:2209.09125},
  year={2022}
}

@inproceedings{rabanser2019failing,
  title={Failing loudly: An empirical study of methods for detecting dataset shift},
  author={Rabanser, Stephan and G{\"u}nnemann, Stephan and Lipton, Zachary},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

% ==================== Safety & Robustness ====================

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{hendrycks2021natural,
  title={Natural adversarial examples},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2021}
}

@inproceedings{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela and Krause, Andreas},
  booktitle={Advances in neural information processing systems},
  year={2017}
}

% ==================== Additional References ====================

@inproceedings{koenig2004gazebo,
  title={Design and use paradigms for gazebo, an open-source multi-robot simulator},
  author={Koenig, Nathan and Howard, Andrew},
  booktitle={IEEE/RSJ international conference on intelligent robots and systems},
  year={2004}
}

@article{tellex2020robots,
  title={Robots that use language},
  author={Tellex, Stefanie and Gopalan, Nakul and Kress-Gazit, Hadas and Matuszek, Cynthia},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={3},
  pages={25--55},
  year={2020}
}

@article{bommasani2021foundation,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

